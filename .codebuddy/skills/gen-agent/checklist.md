# gen-agent 验证清单

本清单用于验证生成的 Agent 是否符合 Anthropic 最佳实践。

## 📋 架构设计检查

### 需求分析
- [ ] **明确了任务类型**
  - [ ] 判断是否真的需要 Agent (vs Workflow vs Single LLM)
  - [ ] 评估了复杂度权衡 (延迟、成本 vs 性能)
  - [ ] 确认了 Agent 的价值 (在什么场景下比简单方案更好)

- [ ] **选择了合适的模式**
  - [ ] 考虑了 6 种 Agentic 模式的适用性
  - [ ] 选择理由清晰,符合任务特点
  - [ ] 如果使用组合模式,解释了为什么需要组合

### 成功标准
- [ ] **定义了明确的成功标准**
  - [ ] 有可量化的指标 (准确率、完成率、用户满意度等)
  - [ ] 有失败的定义 (什么情况下 Agent 失败)
  - [ ] 有中止条件 (最大迭代次数、超时、遇到阻塞)

- [ ] **设计了合理的检查点**
  - [ ] 在关键决策点暂停获取人工反馈
  - [ ] 敏感操作需要人工确认 (如删除、支付)
  - [ ] 检查点不会过于频繁 (避免打断用户)

---

## 🔧 工具设计检查 (ACI)

### 工具定义质量
- [ ] **名称和描述清晰**
  - [ ] 工具名称语义明确 (避免 `do_something`, `process`)
  - [ ] 描述像给初级开发者写 docstring 一样详细
  - [ ] 包含使用场景说明
  - [ ] 说明了与其他工具的区别

- [ ] **参数设计合理**
  - [ ] 参数名称语义清晰
  - [ ] 类型定义准确 (string/number/boolean/enum)
  - [ ] 必填/可选标记正确
  - [ ] 有默认值的参数提供了默认值

- [ ] **包含示例和边界条件**
  - [ ] 提供了正确使用示例
  - [ ] 说明了边界条件 (如长度限制、格式要求)
  - [ ] 说明了常见错误用法
  - [ ] 提供了错误处理说明

### 避免格式开销
- [ ] **降低了格式复杂度**
  - [ ] 避免需要精确计数 (如 diff 的行数、JSON 的层级)
  - [ ] 避免需要字符串转义 (代码写在 JSON 里)
  - [ ] 使用模型熟悉的自然格式 (Markdown > JSON)

- [ ] **给模型思考空间**
  - [ ] 参数设计不会让模型"写入死角"
  - [ ] 有足够的 tokens 让模型生成完整输出
  - [ ] 不需要模型提前做复杂计算

### 防错设计 (Poka-yoke)
- [ ] **应用了防错原则**
  - [ ] 参数设计让错误难以发生 (如绝对路径 vs 相对路径)
  - [ ] 有参数验证和错误提示
  - [ ] 工具返回清晰的成功/失败信号

- [ ] **测试了工具使用**
  - [ ] 在 Anthropic Workbench 测试了多个示例
  - [ ] 观察了模型的错误使用方式
  - [ ] 根据测试结果迭代优化了工具定义

---

## 🔄 实现质量检查

### 主循环设计
- [ ] **包含环境反馈**
  - [ ] 每步执行后从环境获取真实结果 (工具返回值、测试结果)
  - [ ] 基于真实反馈做下一步决策,而非基于假设
  - [ ] 记录了所有环境交互 (用于调试和审计)

- [ ] **有明确的中止条件**
  - [ ] 任务成功完成时中止
  - [ ] 达到最大迭代次数时中止
  - [ ] 遇到无法解决的阻塞时中止
  - [ ] 每个中止条件都有清晰的处理逻辑

- [ ] **包含检查点机制**
  - [ ] 关键决策点暂停获取人工反馈
  - [ ] 检查点设计不影响用户体验
  - [ ] 人工反馈能有效指导后续决策

### 错误处理
- [ ] **完善的错误处理**
  - [ ] 工具调用失败有重试机制 (带指数退避)
  - [ ] 网络错误、超时等异常有处理
  - [ ] 错误信息清晰,便于调试
  - [ ] 错误不会导致 Agent 崩溃

- [ ] **防止错误累积**
  - [ ] 检测连续失败 (如 3 次工具调用失败)
  - [ ] 错误累积到一定程度时中止
  - [ ] 提供错误恢复建议

### 日志和可观测性
- [ ] **详细的日志记录**
  - [ ] 记录每一步的决策和执行
  - [ ] 记录工具调用的参数和返回值
  - [ ] 记录 LLM 的输入和输出 (用于调试)
  - [ ] 日志包含时间戳和上下文信息

- [ ] **可视化的执行过程**
  - [ ] 用户可以看到 Agent 当前在做什么
  - [ ] 显示已完成的步骤和剩余任务
  - [ ] 提供执行进度估计 (如果可能)

---

## 🛡️ 防护和监控检查

### 成本控制
- [ ] **设置了资源限制**
  - [ ] 最大 token 使用量 (单次会话)
  - [ ] 最大 API 调用次数
  - [ ] 每日/每月成本上限
  - [ ] 达到上限时有清晰的处理策略

- [ ] **监控成本使用**
  - [ ] 实时追踪每次运行的成本
  - [ ] 提供成本分析报告 (哪些操作成本高)
  - [ ] 有成本优化建议

### 安全防护
- [ ] **沙箱执行环境**
  - [ ] Agent 在隔离环境中运行
  - [ ] 无法访问生产数据/系统
  - [ ] 测试通过后才上线到生产环境

- [ ] **工具权限限制**
  - [ ] 每个工具只有必要的最小权限
  - [ ] 敏感操作需要额外验证 (如删除、支付)
  - [ ] 有工具调用审计日志

- [ ] **敏感操作保护**
  - [ ] 列出了所有敏感操作
  - [ ] 敏感操作需要人工确认
  - [ ] 禁止 Agent 自动执行敏感操作

### 性能监控
- [ ] **追踪关键指标**
  - [ ] 成功率 (任务完成率)
  - [ ] 平均耗时
  - [ ] 平均迭代次数
  - [ ] 工具调用成功率
  - [ ] 错误率和错误类型分布

- [ ] **建立告警机制**
  - [ ] 成功率低于阈值时告警
  - [ ] 成本超出预算时告警
  - [ ] 出现高频错误时告警

---

## 🎯 三大核心原则检查

### 1. 简洁性 (Simplicity)
- [ ] **从简单方案开始**
  - [ ] 考虑了是否可以用单次 LLM 调用解决
  - [ ] 考虑了是否可以用 Workflow 代替 Agent
  - [ ] 只在必要时才使用 Autonomous Agent

- [ ] **避免过度复杂化**
  - [ ] Agent 的逻辑清晰,没有过多的分支
  - [ ] 工具数量合理 (不超过 10 个)
  - [ ] 没有不必要的抽象层

### 2. 透明性 (Transparency)
- [ ] **清晰展示决策过程**
  - [ ] 用户可以看到 Agent 的"思考"过程
  - [ ] 每一步的理由可以解释
  - [ ] 提供中间结果 (不是黑盒)

- [ ] **可理解的输出**
  - [ ] 最终结果清晰易懂
  - [ ] 失败时提供原因和建议
  - [ ] 输出格式符合用户预期

### 3. 精心设计的 ACI (Agent-Computer Interface)
- [ ] **工具文档完善**
  - [ ] 每个工具都有详细文档
  - [ ] 文档质量像给人类开发者写的一样
  - [ ] 包含示例、边界条件、错误处理

- [ ] **工具设计易用**
  - [ ] 避免格式开销
  - [ ] 参数设计防错
  - [ ] 在 Workbench 充分测试并迭代优化

---

## 🧪 测试覆盖检查

### 功能测试
- [ ] **正常流程测试**
  - [ ] 典型场景可以成功完成
  - [ ] 输出质量符合预期
  - [ ] 用户满意度高

- [ ] **边界条件测试**
  - [ ] 测试了最小输入 (如空字符串、0)
  - [ ] 测试了最大输入 (如超长文本、大数字)
  - [ ] 测试了异常输入 (如错误格式、非法字符)

### 失败场景测试
- [ ] **工具调用失败**
  - [ ] 测试了工具返回错误
  - [ ] 测试了工具超时
  - [ ] 测试了工具返回不符合预期的结果

- [ ] **错误累积测试**
  - [ ] 测试了连续多次工具调用失败
  - [ ] 测试了 Agent 做出错误决策的影响
  - [ ] 验证了错误不会雪崩式累积

### 性能测试
- [ ] **延迟测试**
  - [ ] 测量了平均响应时间
  - [ ] 测试了并发场景 (如果适用)
  - [ ] 验证了延迟在可接受范围内

- [ ] **成本测试**
  - [ ] 估算了单次运行成本
  - [ ] 验证了成本在预算内
  - [ ] 有成本优化方案 (如果成本过高)

---

## 📊 生产就绪检查

### 文档
- [ ] **完整的使用文档**
  - [ ] 使用指南 (如何调用 Agent)
  - [ ] 配置说明 (环境变量、参数)
  - [ ] 示例代码
  - [ ] 常见问题 FAQ

- [ ] **维护文档**
  - [ ] 架构设计文档
  - [ ] 工具设计文档
  - [ ] 故障排查指南
  - [ ] 监控和告警配置

### 部署
- [ ] **部署准备**
  - [ ] 有部署脚本
  - [ ] 有回滚方案
  - [ ] 有健康检查机制
  - [ ] 有灰度发布计划

- [ ] **监控和告警**
  - [ ] 集成了监控系统
  - [ ] 配置了关键指标告警
  - [ ] 有值班人员响应告警

### 维护
- [ ] **持续改进**
  - [ ] 收集用户反馈
  - [ ] 定期分析失败案例
  - [ ] 定期优化工具定义
  - [ ] 定期审查成本和性能

- [ ] **版本管理**
  - [ ] 有版本号管理
  - [ ] 有变更日志
  - [ ] 向后兼容性保证

---

## ✅ 总分评估

| 类别 | 检查项数量 | 通过数量 | 通过率 | 状态 |
|------|-----------|---------|--------|------|
| 架构设计 | 9 | ___ | ___% | ⬜ |
| 工具设计 (ACI) | 16 | ___ | ___% | ⬜ |
| 实现质量 | 14 | ___ | ___% | ⬜ |
| 防护和监控 | 13 | ___ | ___% | ⬜ |
| 三大原则 | 8 | ___ | ___% | ⬜ |
| 测试覆盖 | 12 | ___ | ___% | ⬜ |
| 生产就绪 | 12 | ___ | ___% | ⬜ |
| **总计** | **84** | ___ | ___% | ⬜ |

**评分标准**:
- ✅ **90%+**: 优秀,可以上线生产
- ⚠️ **70-89%**: 良好,需要改进部分问题
- ❌ **<70%**: 需要重大改进

---

## 📌 关键提醒

### 上线前必须通过的检查项
1. ✅ 设置了成本上限和最大迭代次数
2. ✅ 在沙箱环境充分测试
3. ✅ 敏感操作需要人工确认
4. ✅ 有详细的日志和监控
5. ✅ 工具定义在 Workbench 测试并优化
6. ✅ 有明确的失败处理和错误恢复
7. ✅ 错误累积测试通过
8. ✅ 成本和性能在可接受范围内

### 常见遗漏项
- ❌ 忘记设置最大迭代次数 → Agent 可能无限运行
- ❌ 工具文档太简略 → 模型无法正确使用
- ❌ 缺少错误累积检测 → 错误雪崩
- ❌ 没有在 Workbench 测试工具 → 生产环境才发现问题
- ❌ 缺少成本监控 → 成本失控

---

## 🔗 参考资源

- [Building Effective Agents](mdc:spec/global/knowledge/best-practices/BuildingEffectiveAgents.md) - 完整最佳实践文档
- [Anthropic Cookbook - Agent Patterns](https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents) - 代码示例
- [Tool Use Documentation](https://docs.anthropic.com/en/docs/build-with-claude/tool-use) - 工具使用 API 文档
