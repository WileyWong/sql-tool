# ä¸Šä¸‹æ–‡ç®¡ç†æœºåˆ¶

> é•¿ä»»åŠ¡ Agent çš„ä¸Šä¸‹æ–‡ç®¡ç†è®¾è®¡ï¼Œè§£å†³è·¨ä¼šè¯ã€è·¨åŠŸèƒ½çš„ä¸Šä¸‹æ–‡è¿‡å¤§é—®é¢˜ã€‚
> æ”¯æŒ**è½»é‡çº§ RAG æ£€ç´¢**å’Œ**å¤–éƒ¨çŸ¥è¯†åº“å¼•ç”¨**ã€‚

## ğŸ¯ é—®é¢˜èƒŒæ™¯

é•¿ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œä¸Šä¸‹æ–‡ä¼šéšç€è®¾è®¡æ–‡æ¡£çš„ç´¯ç§¯è€Œä¸æ–­å¢é•¿ï¼š

```
ä¼šè¯ 1: éœ€æ±‚åˆ†æ â†’ ç”Ÿæˆ requirement.md (2000 tokens)
ä¼šè¯ 2: æ•°æ®åº“è®¾è®¡ â†’ ç”Ÿæˆ database-design.md (3000 tokens)
ä¼šè¯ 3: API è®¾è®¡ â†’ ç”Ÿæˆ api-design.md (4000 tokens)
ä¼šè¯ 4: ç¼–ç  F005 â†’ éœ€è¦è¯»å–æ‰€æœ‰è®¾è®¡æ–‡æ¡£ (9000+ tokens) â† ä¸Šä¸‹æ–‡çˆ†ç‚¸ï¼
```

**æ ¸å¿ƒé—®é¢˜**ï¼š
- âŒ æ¯æ¬¡ç¼–ç éƒ½è¦è¯»å–å®Œæ•´è®¾è®¡æ–‡æ¡£
- âŒ ä¸Šä¸‹æ–‡ tokens éšåŠŸèƒ½å¢åŠ çº¿æ€§å¢é•¿
- âŒ è·¨ä¼šè¯æ¢å¤æ—¶éœ€è¦é‡æ–°è¯»å–æ‰€æœ‰æ–‡æ¡£
- âŒ æ— æ³•åŒºåˆ†"å¿…éœ€"å’Œ"å¯é€‰"ä¸Šä¸‹æ–‡

## ğŸ—ï¸ è§£å†³æ–¹æ¡ˆæ¶æ„

### ä¸‰å±‚ä¸Šä¸‹æ–‡æ¨¡å‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ä¸Šä¸‹æ–‡ç®¡ç†æ¶æ„                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Layer 1: æ‘˜è¦å±‚ (Summary)                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  feature-list.json ä¸­çš„ context.summary å­—æ®µ              â”‚   â”‚
â”‚  â”‚  - æ¯ä¸ªåŠŸèƒ½çš„ 1-2 å¥è¯æ‘˜è¦                                 â”‚   â”‚
â”‚  â”‚  - çº¦ 50-100 tokens/åŠŸèƒ½                                  â”‚   â”‚
â”‚  â”‚  - ç”¨äºå¿«é€Ÿç†è§£å’Œè·¯ç”±å†³ç­–                                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â†“                                   â”‚
â”‚  Layer 2: ç´¢å¼•å±‚ (Index)                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  design/index.json - è®¾è®¡æ–‡æ¡£ç´¢å¼•                          â”‚   â”‚
â”‚  â”‚  - å®ä½“ â†’ æ–‡æ¡£ä½ç½®æ˜ å°„                                     â”‚   â”‚
â”‚  â”‚  - API â†’ æ–‡æ¡£ä½ç½®æ˜ å°„                                      â”‚   â”‚
â”‚  â”‚  - åŠŸèƒ½ â†’ ç›¸å…³æ–‡æ¡£æ˜ å°„                                     â”‚   â”‚
â”‚  â”‚  - çº¦ 500-1000 tokens                                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â†“                                   â”‚
â”‚  Layer 3: è¯¦æƒ…å±‚ (Detail)                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  å®Œæ•´è®¾è®¡æ–‡æ¡£ (æŒ‰éœ€åŠ è½½)                                    â”‚   â”‚
â”‚  â”‚  - design/requirement.md                                  â”‚   â”‚
â”‚  â”‚  - design/database-design.md                              â”‚   â”‚
â”‚  â”‚  - design/api-design.md                                   â”‚   â”‚
â”‚  â”‚  - ä»…åœ¨éœ€è¦æ—¶è¯»å–ç›¸å…³ section                              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ä¸Šä¸‹æ–‡åŠ è½½ç­–ç•¥

```python
def prepare_context(feature, max_tokens=8000):
    """
    æ™ºèƒ½ä¸Šä¸‹æ–‡å‡†å¤‡ï¼Œç¡®ä¿ä¸è¶…è¿‡ token é™åˆ¶
    
    ç­–ç•¥ï¼š
    1. å§‹ç»ˆåŠ è½½æ‘˜è¦å±‚ (å¿…éœ€ï¼Œçº¦ 100-300 tokens)
    2. åŠ è½½ç›¸å…³ç´¢å¼• (å¿…éœ€ï¼Œçº¦ 200-500 tokens)  
    3. æŒ‰éœ€åŠ è½½è¯¦æƒ…å±‚ (å¯é€‰ï¼ŒæŒ‰ä¼˜å…ˆçº§è£å‰ª)
    """
    context = {}
    tokens_used = 0
    
    # === Layer 1: æ‘˜è¦å±‚ (å§‹ç»ˆåŠ è½½) ===
    summary = feature["context"]["summary"]
    context["summary"] = summary
    tokens_used += estimate_tokens(summary)
    
    # === Layer 2: ç´¢å¼•å±‚ (å§‹ç»ˆåŠ è½½) ===
    index = read_json("design/index.json")
    relevant_index = extract_relevant_index(index, feature)
    context["index"] = relevant_index
    tokens_used += estimate_tokens(relevant_index)
    
    # === Layer 3: è¯¦æƒ…å±‚ (æŒ‰éœ€åŠ è½½) ===
    remaining_tokens = max_tokens - tokens_used - 2000  # é¢„ç•™è¾“å‡ºç©ºé—´
    
    # 3.1 å¿…éœ€ä¸Šä¸‹æ–‡ (ä¼˜å…ˆçº§æœ€é«˜)
    for item in feature["context"]["required"]:
        content = load_context_item(item)
        item_tokens = estimate_tokens(content)
        
        if tokens_used + item_tokens <= max_tokens * 0.7:
            context[item["key"]] = content
            tokens_used += item_tokens
        else:
            # è¶…é™æ—¶ä½¿ç”¨æ‘˜è¦æ›¿ä»£
            context[item["key"]] = item.get("fallback_summary", summary)
    
    # 3.2 å¯é€‰ä¸Šä¸‹æ–‡ (å¡«å……å‰©ä½™ç©ºé—´)
    for item in feature["context"]["optional"]:
        if remaining_tokens > 500:
            content = load_context_item(item)
            item_tokens = estimate_tokens(content)
            
            if item_tokens <= remaining_tokens:
                context[item["key"]] = content
                tokens_used += item_tokens
                remaining_tokens -= item_tokens
    
    return context, tokens_used
```

## ğŸ“‹ æ•°æ®ç»“æ„è®¾è®¡

### 1. feature-list.json æ‰©å±•

```json
{
  "task_id": "user-management-2025-12-05",
  "title": "ç”¨æˆ·ç®¡ç†æ¨¡å—",
  "features": [
    {
      "id": "F005",
      "category": "coding",
      "name": "ç”¨æˆ·æ³¨å†Œæ¥å£",
      "description": "å®ç°ç”¨æˆ·æ³¨å†Œ API",
      
      "context": {
        "summary": "POST /api/user/register, å‚æ•°: username/password/email, è¿”å›: user_id + token, ä¸šåŠ¡è§„åˆ™: ç”¨æˆ·åå”¯ä¸€/å¯†ç åŠ å¯†/é‚®ç®±éªŒè¯",
        
        "required": [
          {
            "key": "api_spec",
            "type": "design_section",
            "file": "design/api-design.md",
            "section": "ç”¨æˆ·æ³¨å†Œæ¥å£",
            "fallback_summary": "POST /api/user/register, å‚æ•°: username/password/email"
          },
          {
            "key": "db_schema",
            "type": "design_section", 
            "file": "design/database-design.md",
            "section": "userè¡¨",
            "fallback_summary": "userè¡¨: id/username/password_hash/email/created_at"
          }
        ],
        
        "optional": [
          {
            "key": "architecture",
            "type": "design_file",
            "file": "design/architecture.md"
          },
          {
            "key": "code_example",
            "type": "code_file",
            "file": "src/common/BaseController.java"
          }
        ],
        
        "dependencies": ["F001", "F002", "F003"],
        
        "estimated_tokens": {
          "summary": 80,
          "required": 1500,
          "optional": 2000,
          "total": 3580
        }
      },
      
      "passes": false,
      "in_progress": true
    }
  ]
}
```

### 2. design/index.json (æ–°å¢)

```json
{
  "version": "1.0",
  "updated_at": "2025-12-05T14:30:00Z",
  
  "entities": {
    "User": {
      "description": "ç”¨æˆ·å®ä½“ï¼ŒåŒ…å«åŸºæœ¬ä¿¡æ¯å’Œè®¤è¯ä¿¡æ¯",
      "table": "t_user",
      "design_refs": {
        "entity": "design/database-design.md#Userå®ä½“",
        "table": "design/database-design.md#userè¡¨",
        "ddl": "design/ddl.sql#CREATE TABLE t_user"
      },
      "related_features": ["F001", "F002", "F005", "F006"],
      "fields": ["id", "username", "password_hash", "email", "phone", "status", "created_at"]
    },
    "Role": {
      "description": "è§’è‰²å®ä½“ï¼Œç”¨äºæƒé™ç®¡ç†",
      "table": "t_role",
      "design_refs": {
        "entity": "design/database-design.md#Roleå®ä½“",
        "table": "design/database-design.md#roleè¡¨"
      },
      "related_features": ["F002", "F007"],
      "fields": ["id", "name", "code", "description"]
    }
  },
  
  "apis": {
    "POST /api/user/register": {
      "description": "ç”¨æˆ·æ³¨å†Œæ¥å£",
      "design_ref": "design/api-design.md#ç”¨æˆ·æ³¨å†Œæ¥å£",
      "related_entities": ["User"],
      "related_features": ["F005"],
      "request": "UserRegisterRequest",
      "response": "UserRegisterResponse"
    },
    "POST /api/user/login": {
      "description": "ç”¨æˆ·ç™»å½•æ¥å£",
      "design_ref": "design/api-design.md#ç”¨æˆ·ç™»å½•æ¥å£",
      "related_entities": ["User"],
      "related_features": ["F006"],
      "request": "UserLoginRequest",
      "response": "UserLoginResponse"
    }
  },
  
  "features": {
    "F001": {
      "name": "éœ€æ±‚åˆ†æ",
      "outputs": ["design/requirement.md"],
      "provides_context_for": ["F002", "F003", "F004"]
    },
    "F002": {
      "name": "æ•°æ®åº“è®¾è®¡",
      "outputs": ["design/database-design.md", "design/ddl.sql"],
      "depends_on": ["F001"],
      "provides_context_for": ["F003", "F005", "F006", "F007"]
    },
    "F003": {
      "name": "APIè®¾è®¡",
      "outputs": ["design/api-design.md"],
      "depends_on": ["F001", "F002"],
      "provides_context_for": ["F005", "F006", "F007"]
    },
    "F005": {
      "name": "ç”¨æˆ·æ³¨å†Œæ¥å£",
      "outputs": ["src/controller/UserController.java", "src/service/UserService.java"],
      "depends_on": ["F002", "F003"],
      "required_context": {
        "from_F002": ["userè¡¨ç»“æ„"],
        "from_F003": ["ç”¨æˆ·æ³¨å†Œæ¥å£è§„æ ¼"]
      }
    }
  }
}
```

### 3. design/summary.md (æ–°å¢)

```markdown
# è®¾è®¡æ‘˜è¦

> è‡ªåŠ¨ç”Ÿæˆçš„è®¾è®¡æ–‡æ¡£æ‘˜è¦ï¼Œç”¨äºå¿«é€Ÿä¸Šä¸‹æ–‡åŠ è½½ã€‚æ¯æ¬¡è®¾è®¡å®Œæˆåè‡ªåŠ¨æ›´æ–°ã€‚

## éœ€æ±‚æ‘˜è¦ (F001)

**æ ¸å¿ƒåŠŸèƒ½**:
- ç”¨æˆ·æ³¨å†Œ: ç”¨æˆ·å/å¯†ç /é‚®ç®±ï¼Œæ”¯æŒé‚®ç®±éªŒè¯
- ç”¨æˆ·ç™»å½•: è´¦å·å¯†ç ç™»å½•ï¼ŒJWT Token è®¤è¯
- æƒé™ç®¡ç†: RBAC æ¨¡å‹ï¼Œè§’è‰²-æƒé™-ç”¨æˆ·ä¸‰çº§å…³ç³»

**ä¸šåŠ¡è§„åˆ™**:
- ç”¨æˆ·å: 4-20å­—ç¬¦ï¼Œå­—æ¯æ•°å­—ä¸‹åˆ’çº¿ï¼Œå”¯ä¸€
- å¯†ç : 8-32å­—ç¬¦ï¼ŒåŒ…å«å­—æ¯å’Œæ•°å­—ï¼ŒBCryptåŠ å¯†
- é‚®ç®±: æ ‡å‡†æ ¼å¼ï¼Œéœ€éªŒè¯ï¼Œå”¯ä¸€

---

## æ•°æ®åº“æ‘˜è¦ (F002)

**è¡¨ç»“æ„**:

| è¡¨å | è¯´æ˜ | æ ¸å¿ƒå­—æ®µ |
|-----|------|---------|
| t_user | ç”¨æˆ·è¡¨ | id, username, password_hash, email, status |
| t_role | è§’è‰²è¡¨ | id, name, code, description |
| t_permission | æƒé™è¡¨ | id, name, code, resource, action |
| t_user_role | ç”¨æˆ·è§’è‰²å…³è” | user_id, role_id |
| t_role_permission | è§’è‰²æƒé™å…³è” | role_id, permission_id |

**å…³é”®ç´¢å¼•**:
- t_user: uk_username, uk_email
- t_role: uk_code

---

## API æ‘˜è¦ (F003)

### ç”¨æˆ·æ³¨å†Œ
- **è·¯å¾„**: POST /api/user/register
- **å‚æ•°**: username(å¿…å¡«), password(å¿…å¡«), email(å¿…å¡«)
- **è¿”å›**: { user_id, token }
- **è§„åˆ™**: ç”¨æˆ·åå”¯ä¸€, å¯†ç åŠ å¯†, é‚®ç®±éªŒè¯

### ç”¨æˆ·ç™»å½•
- **è·¯å¾„**: POST /api/user/login
- **å‚æ•°**: username, password
- **è¿”å›**: { user_id, token, expires_in }
- **è§„åˆ™**: å¯†ç éªŒè¯, JWTç”Ÿæˆ, ç™»å½•æ—¥å¿—

### æƒé™ç®¡ç†
- **è§’è‰²CRUD**: GET/POST/PUT/DELETE /api/roles
- **æƒé™åˆ†é…**: POST /api/roles/{id}/permissions
- **ç”¨æˆ·è§’è‰²**: POST /api/users/{id}/roles

---

## æ¶æ„æ‘˜è¦ (F004)

**æŠ€æœ¯é€‰å‹**:
- åç«¯: Spring Boot 3.2 + MyBatis-Plus 3.5
- æ•°æ®åº“: MySQL 8.0
- è®¤è¯: JWT + Spring Security
- ç¼“å­˜: Redis (Tokenå­˜å‚¨)

**åˆ†å±‚æ¶æ„**:
```
Controller â†’ Service â†’ Mapper â†’ Database
    â†“           â†“
   DTO       Entity
```

**åŒ…ç»“æ„**:
- controller: REST æ¥å£å±‚
- service: ä¸šåŠ¡é€»è¾‘å±‚
- mapper: æ•°æ®è®¿é—®å±‚
- entity: å®ä½“ç±»
- dto: æ•°æ®ä¼ è¾“å¯¹è±¡
- common: å…¬å…±ç»„ä»¶
```

## ğŸ”„ å·¥ä½œæµç¨‹

### 1. è®¾è®¡å®Œæˆæ—¶ç”Ÿæˆæ‘˜è¦

```python
# design-worker å®Œæˆè®¾è®¡å
def on_design_complete(feature, design_doc):
    """
    è®¾è®¡å®Œæˆåçš„é’©å­å‡½æ•°
    """
    # 1. ç”Ÿæˆæ‘˜è¦
    summary = generate_summary(design_doc)
    
    # 2. æ›´æ–° feature-list.json
    update_feature_context(
        feature_id=feature["id"],
        summary=summary,
        required_context=extract_required_context(design_doc),
        estimated_tokens=estimate_tokens(design_doc)
    )
    
    # 3. æ›´æ–°è®¾è®¡ç´¢å¼•
    update_design_index(feature, design_doc)
    
    # 4. æ›´æ–°æ‘˜è¦æ–‡æ¡£
    append_to_summary_doc(feature, summary)
```

### 2. ç¼–ç æ—¶åŠ è½½ä¸Šä¸‹æ–‡

```python
# coding-worker å¼€å§‹ç¼–ç å‰
def prepare_coding_context(feature):
    """
    ä¸ºç¼–ç ä»»åŠ¡å‡†å¤‡ä¸Šä¸‹æ–‡
    """
    # 1. è¯»å–æ‘˜è¦å±‚
    summary = feature["context"]["summary"]
    
    # 2. è¯»å–ç´¢å¼•å±‚
    index = read_json("design/index.json")
    relevant_apis = get_relevant_apis(index, feature)
    relevant_entities = get_relevant_entities(index, feature)
    
    # 3. æŒ‰éœ€è¯»å–è¯¦æƒ…å±‚
    context = {
        "summary": summary,
        "apis": relevant_apis,
        "entities": relevant_entities
    }
    
    # 4. æ£€æŸ¥ token é¢„ç®—
    tokens_used = estimate_tokens(context)
    if tokens_used > 6000:  # é¢„è­¦é˜ˆå€¼
        log_warning(f"ä¸Šä¸‹æ–‡è¾ƒå¤§: {tokens_used} tokens")
    
    return context
```

### 3. è·¨ä¼šè¯æ¢å¤æ—¶

```python
# master-orchestrator ä¼šè¯å¯åŠ¨æ—¶
def session_start():
    """
    ä¼šè¯å¯åŠ¨ï¼Œæ™ºèƒ½æ¢å¤ä¸Šä¸‹æ–‡
    """
    # 1. è¯»å– feature-list.json (åŒ…å«æ‘˜è¦)
    feature_list = read_json("feature-list.json")
    
    # 2. è¯»å–è®¾è®¡ç´¢å¼• (è½»é‡çº§)
    design_index = read_json("design/index.json")
    
    # 3. è¯†åˆ«ä¸‹ä¸€ä¸ªåŠŸèƒ½
    next_feature = select_next_feature(feature_list)
    
    # 4. ä»…åŠ è½½è¯¥åŠŸèƒ½éœ€è¦çš„ä¸Šä¸‹æ–‡
    context = prepare_context(next_feature)
    
    # 5. å±•ç¤ºçŠ¶æ€ (ä¸éœ€è¦è¯»å–å®Œæ•´è®¾è®¡æ–‡æ¡£)
    display_progress(feature_list)
    
    return context
```

## ğŸ“Š Token é¢„ç®—ç®¡ç†

### é¢„ç®—åˆ†é…

| å±‚çº§ | é¢„ç®—å æ¯” | å…¸å‹ tokens | è¯´æ˜ |
|-----|---------|------------|------|
| æ‘˜è¦å±‚ | 5% | 200-400 | å§‹ç»ˆåŠ è½½ |
| ç´¢å¼•å±‚ | 10% | 400-800 | å§‹ç»ˆåŠ è½½ |
| å¿…éœ€è¯¦æƒ… | 50% | 2000-4000 | ä¼˜å…ˆåŠ è½½ |
| å¯é€‰è¯¦æƒ… | 20% | 800-1600 | æŒ‰éœ€åŠ è½½ |
| è¾“å‡ºé¢„ç•™ | 15% | 600-1200 | é¢„ç•™ç»™ç”Ÿæˆ |
| **æ€»è®¡** | 100% | 4000-8000 | å•æ¬¡è°ƒç”¨ä¸Šé™ |

### ç›‘æ§æŒ‡æ ‡

```json
// progress.md ä¸­å¢åŠ ä¸Šä¸‹æ–‡ç›‘æ§
{
  "context_usage": {
    "F001": { "tokens": 1200, "status": "normal" },
    "F002": { "tokens": 2500, "status": "normal" },
    "F003": { "tokens": 3200, "status": "warning" },
    "F005": { "tokens": 4800, "status": "warning" }
  },
  "total_design_tokens": 9700,
  "average_per_feature": 2425,
  "recommendations": [
    "F003 ä¸Šä¸‹æ–‡è¾ƒå¤§(3200 tokens)ï¼Œå»ºè®®ä½¿ç”¨æ‘˜è¦",
    "F005 ç¼–ç æ—¶è€ƒè™‘åˆ†æ‰¹åŠ è½½"
  ]
}
```

## ğŸ› ï¸ å·¥å…·å‡½æ•°

### generate_summary

```python
def generate_summary(design_doc: str, max_tokens: int = 200) -> str:
    """
    ç”Ÿæˆè®¾è®¡æ–‡æ¡£æ‘˜è¦
    
    Args:
        design_doc: å®Œæ•´è®¾è®¡æ–‡æ¡£å†…å®¹
        max_tokens: æ‘˜è¦æœ€å¤§ tokens
    
    Returns:
        ç»“æ„åŒ–æ‘˜è¦å­—ç¬¦ä¸²
    
    æ‘˜è¦æ ¼å¼:
        - API: {method} {path}, å‚æ•°: {params}, è¿”å›: {response}
        - è¡¨: {table_name} ({key_fields})
        - è§„åˆ™: {business_rules}
    """
    # ä½¿ç”¨ LLM ç”Ÿæˆæ‘˜è¦
    prompt = f"""
    è¯·ä¸ºä»¥ä¸‹è®¾è®¡æ–‡æ¡£ç”Ÿæˆç®€æ´æ‘˜è¦ï¼Œæ ¼å¼è¦æ±‚ï¼š
    1. æ¯ä¸ª API ç”¨ä¸€è¡Œæè¿°ï¼šMETHOD /path, å‚æ•°: xxx, è¿”å›: xxx
    2. æ¯ä¸ªè¡¨ç”¨ä¸€è¡Œæè¿°ï¼šè¡¨å (æ ¸å¿ƒå­—æ®µ)
    3. å…³é”®ä¸šåŠ¡è§„åˆ™ç”¨ç®€çŸ­å¥å­
    4. æ€»é•¿åº¦æ§åˆ¶åœ¨ {max_tokens} tokens ä»¥å†…
    
    è®¾è®¡æ–‡æ¡£:
    {design_doc}
    """
    return llm_generate(prompt)
```

### extract_section

```python
def extract_section(file_path: str, section_name: str) -> str:
    """
    ä» Markdown æ–‡ä»¶ä¸­æå–æŒ‡å®š section
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        section_name: section æ ‡é¢˜ (æ”¯æŒæ¨¡ç³ŠåŒ¹é…)
    
    Returns:
        section å†…å®¹
    """
    content = read_file(file_path)
    
    # ä½¿ç”¨æ­£åˆ™åŒ¹é… section
    pattern = rf"(#{1,3}\s*{section_name}.*?)(?=#{1,3}\s|\Z)"
    match = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
    
    if match:
        return match.group(1).strip()
    else:
        return ""
```

### estimate_tokens

```python
def estimate_tokens(text: str) -> int:
    """
    ä¼°ç®—æ–‡æœ¬çš„ token æ•°é‡
    
    ç®€å•ä¼°ç®—: ä¸­æ–‡çº¦ 1.5 å­—/token, è‹±æ–‡çº¦ 4 å­—ç¬¦/token
    """
    chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
    other_chars = len(text) - chinese_chars
    
    return int(chinese_chars / 1.5 + other_chars / 4)
```

## ğŸ” è½»é‡çº§ RAG æ£€ç´¢æœºåˆ¶

### è®¾è®¡ç†å¿µ

é‡‡ç”¨**å…³é”®è¯ç´¢å¼• + æ™ºèƒ½æ£€ç´¢**çš„è½»é‡çº§ RAG æ–¹æ¡ˆï¼Œæ— éœ€å‘é‡æ•°æ®åº“ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     è½»é‡çº§ RAG æ¶æ„                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  ç”¨æˆ·æŸ¥è¯¢ / åŠŸèƒ½æè¿°                                              â”‚
â”‚       â†“                                                         â”‚
â”‚  å…³é”®è¯æå– (extract_keywords)                                   â”‚
â”‚       â†“                                                         â”‚
â”‚  å¤šè·¯æ£€ç´¢:                                                       â”‚
â”‚  â”œâ”€â”€ 1. è®¾è®¡ç´¢å¼•æ£€ç´¢ (design/index.json)                         â”‚
â”‚  â”œâ”€â”€ 2. å…³é”®è¯ç´¢å¼•æ£€ç´¢ (design/keywords.json)                    â”‚
â”‚  â””â”€â”€ 3. å¤–éƒ¨çŸ¥è¯†åº“æ£€ç´¢ (knowledge_bases)                         â”‚
â”‚       â†“                                                         â”‚
â”‚  ç»“æœåˆå¹¶ + ç›¸å…³æ€§æ’åº                                            â”‚
â”‚       â†“                                                         â”‚
â”‚  ä¸Šä¸‹æ–‡ç»„è£… (å— token é¢„ç®—é™åˆ¶)                                   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å…³é”®è¯ç´¢å¼• (design/keywords.json)

```json
{
  "version": "1.0",
  "updated_at": "2025-12-05T14:30:00Z",
  
  "keywords": {
    "ç”¨æˆ·": {
      "features": ["F001", "F002", "F005", "F006"],
      "entities": ["User"],
      "apis": ["POST /api/user/register", "POST /api/user/login"],
      "files": ["design/database-design.md", "design/api-design.md"]
    },
    "æ³¨å†Œ": {
      "features": ["F005"],
      "entities": ["User"],
      "apis": ["POST /api/user/register"],
      "files": ["design/api-design.md#ç”¨æˆ·æ³¨å†Œæ¥å£"]
    },
    "ç™»å½•": {
      "features": ["F006"],
      "entities": ["User"],
      "apis": ["POST /api/user/login"],
      "files": ["design/api-design.md#ç”¨æˆ·ç™»å½•æ¥å£"]
    },
    "æƒé™": {
      "features": ["F007"],
      "entities": ["Role", "Permission"],
      "apis": ["GET /api/roles", "POST /api/roles/{id}/permissions"],
      "files": ["design/database-design.md#æƒé™è¡¨", "design/api-design.md#æƒé™ç®¡ç†"]
    },
    "JWT": {
      "features": ["F004", "F006"],
      "entities": [],
      "apis": ["POST /api/user/login"],
      "files": ["design/architecture.md#è®¤è¯æœºåˆ¶"]
    },
    "RBAC": {
      "features": ["F007"],
      "entities": ["Role", "Permission", "UserRole"],
      "apis": [],
      "files": ["design/database-design.md#RBACæ¨¡å‹"]
    }
  },
  
  "synonyms": {
    "ç™»é™†": "ç™»å½•",
    "æ³¨å†Š": "æ³¨å†Œ",
    "é‰´æƒ": "æƒé™",
    "æˆæƒ": "æƒé™",
    "token": "JWT"
  }
}
```

### RAG æ£€ç´¢å‡½æ•°

```python
def rag_search(query: str, feature: dict, max_results: int = 5) -> list:
    """
    è½»é‡çº§ RAG æ£€ç´¢
    
    Args:
        query: æŸ¥è¯¢æ–‡æœ¬ï¼ˆåŠŸèƒ½æè¿°æˆ–ç”¨æˆ·é—®é¢˜ï¼‰
        feature: å½“å‰åŠŸèƒ½å¯¹è±¡
        max_results: æœ€å¤§è¿”å›ç»“æœæ•°
    
    Returns:
        ç›¸å…³ä¸Šä¸‹æ–‡åˆ—è¡¨ï¼ŒæŒ‰ç›¸å…³æ€§æ’åº
    """
    results = []
    
    # 1. æå–å…³é”®è¯
    keywords = extract_keywords(query)
    
    # 2. åŠ è½½ç´¢å¼•
    design_index = read_json("design/index.json")
    keyword_index = read_json("design/keywords.json")
    
    # 3. å¤šè·¯æ£€ç´¢
    # 3.1 è®¾è®¡ç´¢å¼•æ£€ç´¢
    for keyword in keywords:
        if keyword in design_index.get("entities", {}):
            entity = design_index["entities"][keyword]
            results.append({
                "type": "entity",
                "keyword": keyword,
                "content": entity,
                "relevance": 0.9,
                "source": entity.get("design_ref")
            })
        
        for api_path, api_info in design_index.get("apis", {}).items():
            if keyword in api_path or keyword in api_info.get("description", ""):
                results.append({
                    "type": "api",
                    "keyword": keyword,
                    "content": api_info,
                    "relevance": 0.85,
                    "source": api_info.get("design_ref")
                })
    
    # 3.2 å…³é”®è¯ç´¢å¼•æ£€ç´¢
    for keyword in keywords:
        # åŒä¹‰è¯å¤„ç†
        normalized = keyword_index.get("synonyms", {}).get(keyword, keyword)
        
        if normalized in keyword_index.get("keywords", {}):
            kw_info = keyword_index["keywords"][normalized]
            for file_ref in kw_info.get("files", []):
                results.append({
                    "type": "file",
                    "keyword": normalized,
                    "file": file_ref,
                    "relevance": 0.8,
                    "source": file_ref
                })
    
    # 4. å»é‡å’Œæ’åº
    unique_results = deduplicate_by_source(results)
    sorted_results = sorted(unique_results, key=lambda x: x["relevance"], reverse=True)
    
    return sorted_results[:max_results]

def extract_keywords(text: str) -> list:
    """
    ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯
    
    ç­–ç•¥:
    1. ä¸­æ–‡åˆ†è¯ï¼ˆç®€å•å®ç°ï¼šæŒ‰æ ‡ç‚¹å’Œç©ºæ ¼åˆ†å‰²ï¼‰
    2. è¿‡æ»¤åœç”¨è¯
    3. æå–å®ä½“åè¯
    """
    # ç®€å•å®ç°ï¼šæå–ä¸­æ–‡è¯æ±‡å’Œè‹±æ–‡å•è¯
    import re
    
    # ä¸­æ–‡è¯æ±‡ï¼ˆ2-4å­—ï¼‰
    chinese_words = re.findall(r'[\u4e00-\u9fff]{2,4}', text)
    
    # è‹±æ–‡å•è¯
    english_words = re.findall(r'[a-zA-Z]{3,}', text)
    
    # åœç”¨è¯è¿‡æ»¤
    stopwords = {"çš„", "æ˜¯", "åœ¨", "å’Œ", "äº†", "æœ‰", "ä¸ª", "è¿™", "é‚£", "ä¸€", "ä¸"}
    keywords = [w for w in chinese_words if w not in stopwords]
    keywords.extend([w.lower() for w in english_words])
    
    return list(set(keywords))

def deduplicate_by_source(results: list) -> list:
    """
    æŒ‰ source å»é‡ï¼Œä¿ç•™ç›¸å…³æ€§æœ€é«˜çš„
    """
    seen = {}
    for result in results:
        source = result.get("source", "")
        if source not in seen or result["relevance"] > seen[source]["relevance"]:
            seen[source] = result
    return list(seen.values())
```

### æ™ºèƒ½ä¸Šä¸‹æ–‡æ£€ç´¢

```python
def smart_context_search(feature: dict, query: str = None, max_tokens: int = 8000) -> dict:
    """
    æ™ºèƒ½ä¸Šä¸‹æ–‡æ£€ç´¢ï¼ˆå¢å¼ºç‰ˆï¼‰
    
    1. ä¼˜å…ˆä½¿ç”¨ feature.context ä¸­é¢„å®šä¹‰çš„ä¸Šä¸‹æ–‡
    2. ä½¿ç”¨ RAG æ£€ç´¢è¡¥å……ç›¸å…³ä¸Šä¸‹æ–‡
    3. å¦‚æœæœ‰å¤–éƒ¨çŸ¥è¯†åº“ï¼Œæ£€ç´¢å¹¶åˆå¹¶
    4. æ§åˆ¶æ€» tokens ä¸è¶…è¿‡é¢„ç®—
    
    Args:
        feature: å½“å‰åŠŸèƒ½å¯¹è±¡
        query: é¢å¤–çš„æŸ¥è¯¢æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰
        max_tokens: token é¢„ç®—
    
    Returns:
        context: ç»„è£…å¥½çš„ä¸Šä¸‹æ–‡å­—å…¸
        tokens_used: ä½¿ç”¨çš„ tokens æ•°
    """
    context = {}
    tokens_used = 0
    
    # === 1. åŠ è½½é¢„å®šä¹‰ä¸Šä¸‹æ–‡ï¼ˆæ‘˜è¦ + å¿…éœ€ï¼‰===
    if "context" in feature:
        # æ‘˜è¦å±‚
        summary = feature["context"].get("summary", "")
        context["summary"] = summary
        tokens_used += estimate_tokens(summary)
        
        # å¿…éœ€ä¸Šä¸‹æ–‡
        for item in feature["context"].get("required", []):
            content = load_context_item(item)
            context[item["key"]] = content
            tokens_used += estimate_tokens(content)
    
    # === 2. RAG æ£€ç´¢è¡¥å…… ===
    if query and tokens_used < max_tokens * 0.7:
        rag_query = query or feature.get("description", feature.get("name", ""))
        rag_results = rag_search(rag_query, feature, max_results=3)
        
        for result in rag_results:
            if tokens_used >= max_tokens * 0.85:
                break
            
            # è·³è¿‡å·²åŠ è½½çš„
            if result["source"] in [item.get("file") for item in feature["context"].get("required", [])]:
                continue
            
            content = load_from_source(result["source"])
            item_tokens = estimate_tokens(content)
            
            if tokens_used + item_tokens < max_tokens * 0.85:
                context[f"rag_{result['type']}_{result['keyword']}"] = content
                tokens_used += item_tokens
    
    # === 3. å¤–éƒ¨çŸ¥è¯†åº“æ£€ç´¢ ===
    knowledge_bases = feature.get("knowledge_bases", [])
    if knowledge_bases and tokens_used < max_tokens * 0.9:
        kb_context = search_knowledge_bases(
            knowledge_bases=knowledge_bases,
            query=query or feature.get("description", ""),
            max_tokens=max_tokens - tokens_used - 1000  # é¢„ç•™è¾“å‡ºç©ºé—´
        )
        if kb_context:
            context["external_knowledge"] = kb_context
            tokens_used += estimate_tokens(kb_context)
    
    return context, tokens_used
```

---

## ğŸ“š å¤–éƒ¨çŸ¥è¯†åº“æ”¯æŒ

### è®¾è®¡ç›®æ ‡

æ”¯æŒç”¨æˆ·åœ¨ä»»åŠ¡åˆå§‹åŒ–æ—¶æŒ‡å®šå¤–éƒ¨çŸ¥è¯†åº“ï¼Œå¹¶åœ¨æ•´ä¸ªä»»åŠ¡ç”Ÿå‘½å‘¨æœŸä¸­ä¼ é€’ç»™æ‰€æœ‰ Sub-Agentã€‚

### çŸ¥è¯†åº“é…ç½®æ ¼å¼

```json
{
  "knowledge_bases": [
    {
      "id": "kb_spring_boot",
      "type": "local_docs",
      "name": "Spring Boot å¼€å‘è§„èŒƒ",
      "path": "docs/spring-boot-guide/",
      "description": "å…¬å¸å†…éƒ¨ Spring Boot å¼€å‘è§„èŒƒå’Œæœ€ä½³å®è·µ",
      "file_patterns": ["*.md", "*.txt"],
      "priority": "high"
    },
    {
      "id": "kb_api_standards",
      "type": "local_docs", 
      "name": "API è®¾è®¡è§„èŒƒ",
      "path": "docs/api-standards/",
      "description": "RESTful API è®¾è®¡è§„èŒƒ",
      "file_patterns": ["*.md"],
      "priority": "medium"
    },
    {
      "id": "kb_existing_code",
      "type": "codebase",
      "name": "ç°æœ‰ä»£ç å‚è€ƒ",
      "path": "src/main/java/com/example/",
      "description": "ç°æœ‰é¡¹ç›®ä»£ç ï¼Œç”¨äºä¿æŒé£æ ¼ä¸€è‡´",
      "file_patterns": ["*.java"],
      "priority": "medium"
    },
    {
      "id": "kb_external_api",
      "type": "external_url",
      "name": "ç¬¬ä¸‰æ–¹ API æ–‡æ¡£",
      "url": "https://api.example.com/docs",
      "description": "éœ€è¦é›†æˆçš„ç¬¬ä¸‰æ–¹æœåŠ¡ API æ–‡æ¡£",
      "priority": "low"
    }
  ]
}
```

### feature-list.json ä¸­çš„çŸ¥è¯†åº“å¼•ç”¨

```json
{
  "task_id": "user-management-2025-12-05",
  "title": "ç”¨æˆ·ç®¡ç†æ¨¡å—",
  
  "knowledge_bases": [
    {
      "id": "kb_spring_boot",
      "type": "local_docs",
      "name": "Spring Boot å¼€å‘è§„èŒƒ",
      "path": "docs/spring-boot-guide/",
      "priority": "high"
    },
    {
      "id": "kb_api_standards",
      "type": "local_docs",
      "name": "API è®¾è®¡è§„èŒƒ", 
      "path": "docs/api-standards/",
      "priority": "medium"
    }
  ],
  
  "features": [
    {
      "id": "F005",
      "name": "ç”¨æˆ·æ³¨å†Œæ¥å£",
      "context": {
        "summary": "POST /api/user/register...",
        "required": [...],
        "knowledge_bases": ["kb_spring_boot", "kb_api_standards"]
      }
    }
  ]
}
```

### çŸ¥è¯†åº“æ£€ç´¢å‡½æ•°

```python
def search_knowledge_bases(
    knowledge_bases: list,
    query: str,
    max_tokens: int = 2000
) -> str:
    """
    æ£€ç´¢å¤–éƒ¨çŸ¥è¯†åº“
    
    Args:
        knowledge_bases: çŸ¥è¯†åº“é…ç½®åˆ—è¡¨
        query: æŸ¥è¯¢æ–‡æœ¬
        max_tokens: æœ€å¤§è¿”å› tokens
    
    Returns:
        åˆå¹¶åçš„çŸ¥è¯†åº“å†…å®¹
    """
    results = []
    tokens_used = 0
    
    # æŒ‰ä¼˜å…ˆçº§æ’åº
    sorted_kbs = sorted(
        knowledge_bases,
        key=lambda x: {"high": 0, "medium": 1, "low": 2}.get(x.get("priority", "medium"), 1)
    )
    
    for kb in sorted_kbs:
        if tokens_used >= max_tokens:
            break
        
        kb_content = search_single_kb(kb, query)
        if kb_content:
            content_tokens = estimate_tokens(kb_content)
            if tokens_used + content_tokens <= max_tokens:
                results.append({
                    "source": kb["name"],
                    "content": kb_content
                })
                tokens_used += content_tokens
    
    # æ ¼å¼åŒ–è¾“å‡º
    if not results:
        return ""
    
    output = "## å¤–éƒ¨çŸ¥è¯†åº“å‚è€ƒ\n\n"
    for result in results:
        output += f"### æ¥æº: {result['source']}\n\n"
        output += result["content"] + "\n\n"
    
    return output

def search_single_kb(kb: dict, query: str) -> str:
    """
    æ£€ç´¢å•ä¸ªçŸ¥è¯†åº“
    """
    kb_type = kb.get("type", "local_docs")
    
    if kb_type == "local_docs":
        return search_local_docs(kb["path"], query, kb.get("file_patterns", ["*.md"]))
    
    elif kb_type == "codebase":
        return search_codebase(kb["path"], query, kb.get("file_patterns", ["*.java"]))
    
    elif kb_type == "external_url":
        # å¤–éƒ¨ URL éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œå¯èƒ½éœ€è¦ç¼“å­˜
        return fetch_and_cache_url(kb["url"], query)
    
    return ""

def search_local_docs(path: str, query: str, patterns: list) -> str:
    """
    åœ¨æœ¬åœ°æ–‡æ¡£ç›®å½•ä¸­æœç´¢
    """
    keywords = extract_keywords(query)
    results = []
    
    # éå†æ–‡ä»¶
    for pattern in patterns:
        files = glob.glob(f"{path}/**/{pattern}", recursive=True)
        for file_path in files:
            content = read_file(file_path)
            
            # è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
            score = sum(1 for kw in keywords if kw.lower() in content.lower())
            if score > 0:
                # æå–ç›¸å…³æ®µè½
                relevant_sections = extract_relevant_sections(content, keywords)
                if relevant_sections:
                    results.append({
                        "file": file_path,
                        "score": score,
                        "content": relevant_sections
                    })
    
    # æ’åºå¹¶è¿”å› Top ç»“æœ
    results.sort(key=lambda x: x["score"], reverse=True)
    
    output = ""
    for result in results[:3]:  # Top 3
        output += f"**æ–‡ä»¶: {result['file']}**\n\n"
        output += result["content"] + "\n\n"
    
    return output

def extract_relevant_sections(content: str, keywords: list, context_lines: int = 5) -> str:
    """
    ä»æ–‡æ¡£ä¸­æå–åŒ…å«å…³é”®è¯çš„ç›¸å…³æ®µè½
    """
    lines = content.split("\n")
    relevant_ranges = set()
    
    for i, line in enumerate(lines):
        for keyword in keywords:
            if keyword.lower() in line.lower():
                # æ·»åŠ ä¸Šä¸‹æ–‡è¡Œ
                start = max(0, i - context_lines)
                end = min(len(lines), i + context_lines + 1)
                for j in range(start, end):
                    relevant_ranges.add(j)
    
    if not relevant_ranges:
        return ""
    
    # åˆå¹¶è¿ç»­èŒƒå›´
    sorted_ranges = sorted(relevant_ranges)
    sections = []
    current_section = [sorted_ranges[0]]
    
    for i in range(1, len(sorted_ranges)):
        if sorted_ranges[i] - sorted_ranges[i-1] <= 2:
            current_section.append(sorted_ranges[i])
        else:
            sections.append(current_section)
            current_section = [sorted_ranges[i]]
    sections.append(current_section)
    
    # æå–å†…å®¹
    output = ""
    for section in sections[:3]:  # æœ€å¤š 3 ä¸ªæ®µè½
        section_content = "\n".join(lines[section[0]:section[-1]+1])
        output += section_content + "\n\n---\n\n"
    
    return output.strip()
```

### çŸ¥è¯†åº“ä¼ é€’æœºåˆ¶

ç¡®ä¿çŸ¥è¯†åº“é…ç½®åœ¨æ•´ä¸ªä»»åŠ¡ç”Ÿå‘½å‘¨æœŸä¸­æ­£ç¡®ä¼ é€’ç»™æ‰€æœ‰ Sub-Agentï¼š

```python
def dispatch_worker_with_knowledge(feature: dict, task_config: dict) -> dict:
    """
    è°ƒåº¦ Worker æ—¶ä¼ é€’çŸ¥è¯†åº“é…ç½®
    
    Args:
        feature: å½“å‰åŠŸèƒ½
        task_config: ä»»åŠ¡çº§é…ç½®ï¼ˆåŒ…å«çŸ¥è¯†åº“ï¼‰
    
    Returns:
        Worker æ‰§è¡Œç»“æœ
    """
    # 1. å‡†å¤‡ä¸Šä¸‹æ–‡
    context, tokens_used = smart_context_search(
        feature=feature,
        query=feature.get("description"),
        max_tokens=8000
    )
    
    # 2. è·å–åŠŸèƒ½çº§çŸ¥è¯†åº“å¼•ç”¨
    feature_kb_ids = feature.get("context", {}).get("knowledge_bases", [])
    
    # 3. ä»ä»»åŠ¡é…ç½®ä¸­è·å–å®Œæ•´çŸ¥è¯†åº“é…ç½®
    task_knowledge_bases = task_config.get("knowledge_bases", [])
    
    # 4. è¿‡æ»¤å‡ºåŠŸèƒ½éœ€è¦çš„çŸ¥è¯†åº“
    if feature_kb_ids:
        relevant_kbs = [kb for kb in task_knowledge_bases if kb["id"] in feature_kb_ids]
    else:
        # å¦‚æœåŠŸèƒ½æ²¡æœ‰æŒ‡å®šï¼Œä½¿ç”¨æ‰€æœ‰é«˜ä¼˜å…ˆçº§çŸ¥è¯†åº“
        relevant_kbs = [kb for kb in task_knowledge_bases if kb.get("priority") == "high"]
    
    # 5. æ„å»º Worker è°ƒç”¨å‚æ•°
    worker_params = {
        "feature": feature,
        "context": context,
        "knowledge_bases": relevant_kbs,  # ä¼ é€’çŸ¥è¯†åº“é…ç½®
        "tokens_used": tokens_used
    }
    
    # 6. è°ƒåº¦ Worker
    if feature["category"] == "design":
        return invoke_worker("design-worker", **worker_params)
    elif feature["category"] == "coding":
        return invoke_worker("coding-worker", **worker_params)
    elif feature["category"] == "testing":
        return invoke_worker("coding-worker", **worker_params)
```

### Worker Agent æ¥æ”¶çŸ¥è¯†åº“

Worker Agent éœ€è¦åœ¨æ‰§è¡Œæ—¶ä½¿ç”¨ä¼ é€’çš„çŸ¥è¯†åº“ï¼š

```python
# design-worker / coding-worker ä¸­

def execute_with_knowledge(feature: dict, context: dict, knowledge_bases: list):
    """
    ä½¿ç”¨çŸ¥è¯†åº“æ‰§è¡Œä»»åŠ¡
    """
    # 1. åŸºç¡€ä¸Šä¸‹æ–‡
    full_context = context.copy()
    
    # 2. æ£€ç´¢çŸ¥è¯†åº“è¡¥å……ä¸Šä¸‹æ–‡
    if knowledge_bases:
        kb_content = search_knowledge_bases(
            knowledge_bases=knowledge_bases,
            query=feature.get("description", feature["name"]),
            max_tokens=2000
        )
        if kb_content:
            full_context["knowledge_base_reference"] = kb_content
    
    # 3. æ‰§è¡Œä»»åŠ¡ï¼ˆè®¾è®¡/ç¼–ç /æµ‹è¯•ï¼‰
    result = execute_task(feature, full_context)
    
    return result
```

---

## ğŸ”„ ç´¢å¼•è‡ªåŠ¨æ›´æ–°

### è®¾è®¡å®Œæˆæ—¶æ›´æ–°ç´¢å¼•

```python
def on_design_complete(feature: dict, design_doc_path: str):
    """
    è®¾è®¡å®Œæˆåè‡ªåŠ¨æ›´æ–°ç´¢å¼•
    """
    # 1. è¯»å–è®¾è®¡æ–‡æ¡£
    content = read_file(design_doc_path)
    
    # 2. ç”Ÿæˆæ‘˜è¦
    summary = generate_summary(content)
    
    # 3. æå–å…³é”®è¯
    keywords = extract_keywords(content)
    
    # 4. æ›´æ–° design/index.json
    update_design_index(feature, content)
    
    # 5. æ›´æ–° design/keywords.json
    update_keyword_index(feature, keywords, design_doc_path)
    
    # 6. æ›´æ–° feature-list.json ä¸­çš„ context
    update_feature_context(feature["id"], {
        "summary": summary,
        "keywords": keywords
    })
    
    # 7. è¿½åŠ åˆ° design/summary.md
    append_to_summary_doc(feature, summary)

def update_keyword_index(feature: dict, keywords: list, file_path: str):
    """
    æ›´æ–°å…³é”®è¯ç´¢å¼•
    """
    index_path = "design/keywords.json"
    
    if file_exists(index_path):
        index = read_json(index_path)
    else:
        index = {"version": "1.0", "keywords": {}, "synonyms": {}}
    
    # æ›´æ–°æ¯ä¸ªå…³é”®è¯
    for keyword in keywords:
        if keyword not in index["keywords"]:
            index["keywords"][keyword] = {
                "features": [],
                "entities": [],
                "apis": [],
                "files": []
            }
        
        kw_info = index["keywords"][keyword]
        
        # æ·»åŠ åŠŸèƒ½å¼•ç”¨
        if feature["id"] not in kw_info["features"]:
            kw_info["features"].append(feature["id"])
        
        # æ·»åŠ æ–‡ä»¶å¼•ç”¨
        if file_path not in kw_info["files"]:
            kw_info["files"].append(file_path)
    
    # æ›´æ–°æ—¶é—´æˆ³
    index["updated_at"] = datetime.now().isoformat()
    
    # ä¿å­˜
    write_json(index_path, index)
```

---

## âœ… å®æ–½æ¸…å•

### Phase 1: æ•°æ®ç»“æ„æ‰©å±• (ç«‹å³å®æ–½)

- [x] ä¿®æ”¹ `feature-list.json` æ ¼å¼ï¼Œå¢åŠ  `context` å­—æ®µ
- [x] åˆ›å»º `design/index.json` ç´¢å¼•æ–‡ä»¶
- [x] åˆ›å»º `design/summary.md` æ‘˜è¦æ–‡ä»¶
- [x] åˆ›å»º `design/keywords.json` å…³é”®è¯ç´¢å¼•æ–‡ä»¶ï¼ˆæ¨¡æ¿å·²å®šä¹‰ï¼Œè¿è¡Œæ—¶ç”Ÿæˆï¼‰

### Phase 2: Agent ä¿®æ”¹ (æœ¬æ¬¡å®æ–½)

- [x] ä¿®æ”¹ `master-orchestrator.md` å¢åŠ ä¸Šä¸‹æ–‡å‡†å¤‡é€»è¾‘
- [x] ä¿®æ”¹ `design-worker.md` å¢åŠ æ‘˜è¦ç”Ÿæˆæ­¥éª¤
- [x] ä¿®æ”¹ `coding-worker.md` å¢åŠ ä¸Šä¸‹æ–‡åŠ è½½é€»è¾‘
- [x] ä¿®æ”¹ `initializer.md` å¢åŠ åˆå§‹åŒ–ç´¢å¼•æ–‡ä»¶å’ŒçŸ¥è¯†åº“é…ç½®

### Phase 3: è½»é‡çº§ RAG (æœ¬æ¬¡å®æ–½)

- [x] å®ç° `extract_keywords()` å…³é”®è¯æå–ï¼ˆä¼ªä»£ç å·²å®šä¹‰ï¼‰
- [x] å®ç° `rag_search()` RAG æ£€ç´¢ï¼ˆä¼ªä»£ç å·²å®šä¹‰ï¼‰
- [x] å®ç° `smart_context_search()` æ™ºèƒ½ä¸Šä¸‹æ–‡æ£€ç´¢ï¼ˆä¼ªä»£ç å·²å®šä¹‰ï¼‰
- [x] å®ç°ç´¢å¼•è‡ªåŠ¨æ›´æ–°æœºåˆ¶ï¼ˆdesign-worker æ­¥éª¤ 4ï¼‰

### Phase 4: å¤–éƒ¨çŸ¥è¯†åº“æ”¯æŒ (æœ¬æ¬¡å®æ–½)

- [x] å®ç° `search_knowledge_bases()` çŸ¥è¯†åº“æ£€ç´¢ï¼ˆä¼ªä»£ç å·²å®šä¹‰ï¼‰
- [x] å®ç°çŸ¥è¯†åº“é…ç½®è§£æï¼ˆinitializer æ­¥éª¤ 2.5ï¼‰
- [x] å®ç°çŸ¥è¯†åº“ä¼ é€’æœºåˆ¶ï¼ˆmaster-orchestrator dispatch_workerï¼‰
- [x] æ›´æ–° Worker Agent æ¥æ”¶çŸ¥è¯†åº“ï¼ˆcoding-worker æ­¥éª¤ 1ï¼‰

### Phase 5: ç›‘æ§å¢å¼º (åç»­ä¼˜åŒ–)

- [ ] åœ¨ `progress.md` ä¸­å¢åŠ ä¸Šä¸‹æ–‡ä½¿ç”¨ç»Ÿè®¡
- [ ] å¢åŠ  token é¢„è­¦æœºåˆ¶
- [ ] å¢åŠ ä¸Šä¸‹æ–‡å‹ç¼©å»ºè®®
- [ ] å¢åŠ çŸ¥è¯†åº“å‘½ä¸­ç‡ç»Ÿè®¡

## ğŸ”— ç›¸å…³èµ„æº

- [master-orchestrator.md](../../agents/master-orchestrator.md) - ä»»åŠ¡æ€»æ§ Agent
- [design-worker.md](../../agents/design-worker.md) - è®¾è®¡ Worker
- [coding-worker.md](../../agents/coding-worker.md) - ç¼–ç  Worker
- [Anthropic Long-Running Agents](https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents) - å®˜æ–¹æœ€ä½³å®è·µ

---

**ç‰ˆæœ¬**: 1.0.0  
**æœ€åæ›´æ–°**: 2025-12-05  
**ç»´æŠ¤è€…**: Spec-Code Team
